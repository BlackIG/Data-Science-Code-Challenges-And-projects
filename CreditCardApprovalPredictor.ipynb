{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250ac15e",
   "metadata": {},
   "source": [
    "<center> <h1>CreditCardApprovalPredictor:</h1><h2> A Logistic Regression Model for Credit Card Application Approval</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd7cf2e",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/credit_card.jpg\"\n",
    "     alt=\"Learn good habits to avoid modelling debt\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "Learn good habits to avoid modelling debt... Photo by <a href=\"https://unsplash.com/@rupixen?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\"> Rupixen.com </a> on Unsplash. <br> Project completed by Ikechukwu Chilaka\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddc273",
   "metadata": {},
   "source": [
    "### 1.0 Introduction\n",
    "In this challenge project, I will begin a practical experience of building models for classification problems.using basic Logistic Regression model.  \n",
    "\n",
    "#### 1.1 Objective\n",
    "- Implement a logistic regression model from scratch to solve a classification problem.\n",
    "- Apply learned concepts to preprocess data, fit the model, and evaluate its performance.\n",
    "- Enhance problem-solving skills by addressing a real-world classification challenge.\n",
    "\n",
    "#### 1.2 Method\n",
    "- First, I started off by loading and viewing the dataset.\n",
    "- I discovered that the dataset has a mixture of both numerical and non-numerical features; that it contains values from different ranges; and that it contains a number of missing entries.\n",
    " - Based upon the observations above, I carried out preprocessing steps on the dataset to ensure the machine learning model I choose can make good predictions.\n",
    " - Once the data was in good shape, I did some exploratory data analysis to build my intuitions.\n",
    " - Finally, I built a machine learning model that can predict if an individual's application for a credit card will be accepted.\n",
    " \n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63dda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480d7ef",
   "metadata": {},
   "source": [
    "### 2.0  The Dataset\n",
    "I will use the [Credit Card Approval dataset](http://archive.ics.uci.edu/ml/datasets/credit+approval) from the UCI Machine Learning Repository.\n",
    "\n",
    "The variables within this dataset will be explored in the sections below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80c841",
   "metadata": {},
   "source": [
    "#### 2.1 Reading in the data\n",
    "\n",
    "First, loading and viewing the dataset. We find that since this data are confidential, the contributor of the dataset has anonymized the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977b6832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/89fee4463f428f55d31a254924e18501a3c468c3/Data/classification_sprint/cc_approvals.data',header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c798da3",
   "metadata": {},
   "source": [
    "The output may appear a bit confusing at first glance, but I will try to figure out the most important features of a credit card application. The features of this dataset have been anonymized to protect the privacy, but [this blog](http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html) gives us a pretty good overview of the probable features. The probable features in a typical credit card application are <code>Gender</code>, <code>Age</code>, <code>Debt</code>, <code>Married</code>, <code>BankCustomer</code>, <code>EducationLevel</code>, <code>Ethnicity</code>, <code>YearsEmployed</code>, <code>PriorDefault</code>, <code>Employed</code>, <code>CreditScore</code>, <code>DriversLicense</code>, <code>Citizen</code>, <code>ZipCode</code>, <code>Income</code> and finally the <code>ApprovalStatus</code>. \n",
    "\n",
    "This gives  a pretty good starting point, and I can map these features with respect to the columns in the output.   \n",
    "\n",
    "From our first glance at the data, the dataset has a mixture of numerical and non-numerical features. This can be fixed with some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e75c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>b</td>\n",
       "      <td>47.17</td>\n",
       "      <td>5.835</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>5.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00465</td>\n",
       "      <td>150</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>b</td>\n",
       "      <td>25.83</td>\n",
       "      <td>12.835</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>v</td>\n",
       "      <td>0.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>a</td>\n",
       "      <td>50.25</td>\n",
       "      <td>0.835</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00240</td>\n",
       "      <td>117</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>?</td>\n",
       "      <td>29.50</td>\n",
       "      <td>2.000</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00256</td>\n",
       "      <td>17</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>a</td>\n",
       "      <td>37.33</td>\n",
       "      <td>2.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>h</td>\n",
       "      <td>0.210</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>246</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>a</td>\n",
       "      <td>41.58</td>\n",
       "      <td>1.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.665</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00240</td>\n",
       "      <td>237</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>a</td>\n",
       "      <td>30.58</td>\n",
       "      <td>10.665</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>0.085</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>12</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00129</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>b</td>\n",
       "      <td>19.42</td>\n",
       "      <td>7.250</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>a</td>\n",
       "      <td>17.92</td>\n",
       "      <td>10.210</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>50</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>a</td>\n",
       "      <td>20.08</td>\n",
       "      <td>1.250</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>b</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.290</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>364</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.000</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>3.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00176</td>\n",
       "      <td>537</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>b</td>\n",
       "      <td>17.08</td>\n",
       "      <td>3.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>v</td>\n",
       "      <td>0.335</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00140</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>b</td>\n",
       "      <td>36.42</td>\n",
       "      <td>0.750</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>v</td>\n",
       "      <td>0.585</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00240</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>b</td>\n",
       "      <td>40.58</td>\n",
       "      <td>3.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>3.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "      <td>00400</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>b</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>1.250</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>a</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>394</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>a</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>b</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>750</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>b</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>8.290</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
       "670  b  47.17   5.835  u  g   w   v  5.500  f  f   0  f  g  00465  150  -\n",
       "671  b  25.83  12.835  u  g  cc   v  0.500  f  f   0  f  g  00000    2  -\n",
       "672  a  50.25   0.835  u  g  aa   v  0.500  f  f   0  t  g  00240  117  -\n",
       "673  ?  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n",
       "674  a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n",
       "675  a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n",
       "676  a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n",
       "677  b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n",
       "678  a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n",
       "679  a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n",
       "680  b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
       "681  b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
       "682  b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
       "683  b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
       "684  b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
       "685  b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
       "686  a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
       "687  a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
       "688  b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
       "689  b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f594337",
   "metadata": {},
   "source": [
    "<li>The dataset contains both numeric and non-numeric data (specifically data that are of <code>float64</code>, <code>int64</code> and <code>object</code> types). Specifically, features 2, 7, 10 and 14 contain numeric values (of types float64, float64, int64 and int64, respectively) and all the other features contain non-numeric values.</li><br>\n",
    "<li>The dataset also contains values from several ranges. Some features have a value range of 0 - 28, some have a range of 2 - 67, and some have a range of 1017 - 100000.</br> \n",
    "<br>    \n",
    "<li>Finally, the dataset has missing values, which I will take care of in this task. The missing values in the dataset are labelled with '?', which can be seen in the last cell's output.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f12d37",
   "metadata": {},
   "source": [
    "#### 2.2 Cleaning the data\n",
    "\n",
    "* Replace the '?'s with NaN.\n",
    "* Impute the missing values with mean imputation.\n",
    "* Impute the missing values of non-numeric columns with the most frequent values as present in the respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d3e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data, column_name):\n",
    "    \"\"\"\n",
    "    Cleans the data by replacing missing values and imputing missing values.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The pandas DataFrame to clean.\n",
    "        column_name (str): The column name to calculate the unique value counts.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of counts of unique values in the specified column.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If 'data' is not a DataFrame or 'column_name' is not in data.\n",
    "    \"\"\"\n",
    "    # Ensure input is a DataFrame\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise ValueError(\"Data input is not a DataFrame\")\n",
    "\n",
    "    # Ensure column name is in the DataFrame\n",
    "    if column_name not in data.columns:\n",
    "        raise ValueError(f\"{column_name} is not a column in the data\")\n",
    "\n",
    "    # Replace '?' with NaN\n",
    "    data = data.replace('?', np.nan)\n",
    "    \n",
    "    # Impute missing values\n",
    "    # Treating numeric columns first - fill with mean\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype in ['float64', 'int64']:\n",
    "            # Since missing values are NaN, astype(float) will exclude them in the calculation\n",
    "            mean_calc = data[column].astype(float).mean()\n",
    "            data[column] = data[column].astype(float).fillna(mean_calc)\n",
    "        else:\n",
    "            # Treating non-numeric - fill with most frequent value\n",
    "            most_frequent_value = data[column].mode().iloc[0]\n",
    "            data[column] = data[column].fillna(most_frequent_value)\n",
    "    \n",
    "    # Return the count of unique values in the specified column\n",
    "    return list(data[column_name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5e9672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[480, 210]\n",
      "[395, 295]\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "print(data_cleaning(df, 0))\n",
    "print(data_cleaning(df, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155f966",
   "metadata": {},
   "source": [
    "**Expected Outputs:**\n",
    "\n",
    "```python\n",
    "\n",
    "    data_cleaning(df, 0) == [480, 210]\n",
    "    data_cleaning(df, 9) == [395, 295]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8294d3aa",
   "metadata": {},
   "source": [
    "#### 2.3 Data Preprocessing\n",
    "\n",
    "* Convert the non-numeric data into numeric using sklearn's ```labelEncoder``` \n",
    "* Drop the features 11 and 13 and convert the DataFrame to a NumPy array\n",
    "* Split the data into features and labels\n",
    "* Standardise the features using sklearn's ```MinMaxScaler```\n",
    "* Split the data into 80% training and 20% testing data.\n",
    "* Use the `train_test_split` method from `sklearn` to do this.\n",
    "* Set random_state to equal 42 for this internal method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb67622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(df):\n",
    "    \"\"\"\n",
    "    Processes the input DataFrame for classification tasks by encoding, scaling, and splitting.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The raw, unprocessed dataframe.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two tuples containing the training and testing data splits: ((X_train, y_train), (X_test, y_test)).\n",
    "    \"\"\"\n",
    "    # Initialize LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Convert non-numeric columns to numeric using LabelEncoder\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "    # Drop the features 11 and 13\n",
    "    df = df.drop(columns=[df.columns[11], df.columns[13]])\n",
    "\n",
    "    # Convert DataFrame to a NumPy array\n",
    "    data_np = df.values\n",
    "    \n",
    "    # Split data into features and labels (assuming the last column is the label) - standard convention\n",
    "    X = data_np[:, :-1]\n",
    "    y = data_np[:, -1]\n",
    "    \n",
    "    # Standardize the features using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the data into 80% training and 20% testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b7c0e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.25787966 0.48214286 1.         1.         0.42857143\n",
      "  0.33333333 0.         0.         0.         0.         0.\n",
      "  0.        ]]\n",
      "[1.]\n",
      "[[0.5        1.         0.05357143 0.66666667 0.33333333 0.42857143\n",
      "  0.33333333 0.         0.         1.         0.02985075 0.\n",
      "  0.00105   ]]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[:1])\n",
    "print(y_train[:1])\n",
    "print(X_test[:1])\n",
    "print(y_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f7077",
   "metadata": {},
   "source": [
    "**Expected Outputs:*\n",
    "\n",
    "```python\n",
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[:1])\n",
    "print(y_train[:1])\n",
    "print(X_test[:1])\n",
    "print(y_test[:1])\n",
    "```\n",
    "\n",
    "> ```\n",
    "[[1.         0.25787966 0.48214286 1.         1.         0.42857143\n",
    "  0.33333333 0.         0.         0.         0.         0.\n",
    "  0.        ]]\n",
    "[1.]\n",
    "[[0.5        1.         0.05357143 0.66666667 0.33333333 0.42857143\n",
    "  0.33333333 0.         0.         1.         0.02985075 0.\n",
    "  0.00105   ]]\n",
    "[1.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd1d11",
   "metadata": {},
   "source": [
    "### 3.0 Training the model\n",
    "\n",
    "Now that I have formatted our data, I can fit a model using sklearn's `LogisticRegression` class with solver 'lbfgs'. I will write a function that will take as input `(X_train, y_train)` that I created previously, and return a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62e219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a logistic regression model on the provided training data.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (numpy.array): The training feature dataset.\n",
    "        y_train (numpy.array): The training label dataset.\n",
    "\n",
    "    Returns:\n",
    "        LogisticRegression: A logistic regression model fitted to the training data.\n",
    "    \"\"\"\n",
    "    # Create a logistic regression model with the 'lbfgs' solver\n",
    "    model = LogisticRegression(solver='lbfgs')  \n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261abd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5068926456002565\n",
      "[[ 0.25237869 -0.22847881 -0.01779302  2.00977742  0.23903441 -0.29504922\n",
      "  -0.08952344 -0.83468871 -3.48756932 -1.07648711 -0.83688921  0.07860585\n",
      "  -1.3077735 ]]\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "lm = train_model(X_train, y_train)\n",
    "print(lm.intercept_[0])\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd3417",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "\n",
    "```python\n",
    "lm = train_model(X_train, y_train)\n",
    "print(lm.intercept_[0])\n",
    "print(lm.coef_)\n",
    "```\n",
    "```\n",
    "1.5068926456005878\n",
    "[[ 0.25237869 -0.22847881 -0.01779302  2.00977742  0.23903441 -0.29504922\n",
    "  -0.08952344 -0.83468871 -3.48756932 -1.07648711 -0.83688921  0.07860585\n",
    "  -1.3077735 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a296c30",
   "metadata": {},
   "source": [
    "### 4.0 Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86dc23",
   "metadata": {},
   "source": [
    "#### 4.1 AUC - ROC curve\n",
    "\n",
    "AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Write a function which returns the roc auc score of the trained model when tested with the test set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a `float` of the roc auc score of the model. This number should be between zero and one.\n",
    "\n",
    "_**Note**_  The positive class's probability as the score is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556d5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_score(lm, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Computes the ROC AUC score for the provided test data and a fitted model.\n",
    "\n",
    "    Parameters:\n",
    "        lm (LogisticRegression): The fitted logistic regression model.\n",
    "        X_test (numpy.array): The test feature dataset.\n",
    "        y_test (numpy.array): The actual labels of the test dataset.\n",
    "\n",
    "    Returns:\n",
    "        float: The ROC AUC score of the model on the test data.\n",
    "    \"\"\"\n",
    "    # Get the probability scores for the positive class\n",
    "    y_scores = lm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate the ROC AUC score\n",
    "    auc_score = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc3cba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8865546218487395\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "print(roc_score(lm,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1225354",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "    \n",
    "```python\n",
    "print(roc_score(lm,X_test,y_test))\n",
    "```\n",
    ">```\n",
    "0.8865546218487395\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7ff9b",
   "metadata": {},
   "source": [
    "#### 4.1 Accuracy, Precision, Recall and F1 scores.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a tuple in the form (`Accuracy`, `Precision`, `Recall`, `F1-Score`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49bcaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(lm, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Calculates the Accuracy, Precision, Recall, and F1-Score of the fitted logistic regression model.\n",
    "\n",
    "    Parameters:\n",
    "        lm (LogisticRegression): The fitted logistic regression model.\n",
    "        X_test (numpy.array): The test feature dataset.\n",
    "        y_test (numpy.array): The actual labels of the test dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the Accuracy, Precision, Recall, and F1-Score.\n",
    "    \"\"\"\n",
    "    # Predict the labels for the test set\n",
    "    y_pred = lm.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #handle cases where there are no true positives by setting zero_division=0 in the precision_score call, which avoids division by zero errors by returning 0 in such cases.\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    return (accuracy, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f261af9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.833333\n",
      "Precision: 0.846154\n",
      "Recall: 0.808824\n",
      "F1 score: 0.827068\n"
     ]
    }
   ],
   "source": [
    "(accuracy, precision, recall, f1) = scores(lm,X_test,y_test)\n",
    "    \n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0b488",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "(accuracy, precision, recall, f1) = scores(lm,X_test,y_test)\n",
    "    \n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)\n",
    "```\n",
    "> ```\n",
    "Accuracy: 0.833333\n",
    "Precision: 0.846154\n",
    "Recall: 0.808824\n",
    "F1 score: 0.827068\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
